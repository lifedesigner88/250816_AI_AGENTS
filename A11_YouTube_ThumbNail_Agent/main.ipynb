{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "import base64\n",
    "import operator, textwrap, dotenv\n",
    "\n",
    "dotenv.load_dotenv()\n",
    "\n",
    "from langchain.chat_models import init_chat_model\n",
    "from langgraph.types import Send, interrupt\n",
    "from typing_extensions import Annotated\n",
    "\n",
    "from langgraph.graph import END, START, StateGraph\n",
    "from typing import TypedDict\n",
    "import subprocess\n",
    "\n",
    "# 오픈 AI 직접 사용 하는 방식.\n",
    "from openai import OpenAI\n",
    "\n",
    "llm = init_chat_model(\"openai:gpt-4o-mini\")\n",
    "\n",
    "\n",
    "class State(TypedDict):\n",
    "    video_file: str\n",
    "    audio_file: str\n",
    "    transcription: str\n",
    "    summaries: Annotated[list[str], operator.add]\n",
    "    thumbnail_prompt: Annotated[list[str], operator.add]\n",
    "    thumbnail_sketches: Annotated[list[str], operator.add]\n",
    "    mega_summarys: str\n",
    "    user_feedback: str\n",
    "    chosen_prompt: str\n",
    "\n",
    "\n",
    "def extract_audio(state: State):\n",
    "    output_file = state[\"video_file\"].replace(\".mp4\", \".mp3\")\n",
    "    command = [\n",
    "        \"ffmpeg\",\n",
    "        \"-i\",\n",
    "        state[\"video_file\"],\n",
    "        \"-filter:a\",\n",
    "        \"atempo=2.0\",\n",
    "        \"-y\",\n",
    "        output_file,\n",
    "    ]\n",
    "    subprocess.run(command)\n",
    "    return {\n",
    "        \"audio_file\": output_file,\n",
    "    }\n",
    "\n",
    "\n",
    "def transcribe_audio(state: State):\n",
    "    client = OpenAI()\n",
    "    with open(state[\"audio_file\"], \"rb\") as audio_file:\n",
    "        transcription = client.audio.transcriptions.create(\n",
    "            model=\"whisper-1\",\n",
    "            response_format=\"text\",\n",
    "            file=audio_file,\n",
    "            language=\"ko\",\n",
    "            prompt=\"유발하라리, 넥서스, 책 요약\"\n",
    "        )\n",
    "        return {\n",
    "            \"transcription\": transcription\n",
    "        }\n",
    "\n",
    "\n",
    "def dispatch_summarizers(state: State):\n",
    "    transcription = state[\"transcription\"]\n",
    "    chunks = []\n",
    "    for i, chunk in enumerate(textwrap.wrap(transcription, 500)):\n",
    "        chunks.append({\n",
    "            \"id\": i + 1,\n",
    "            \"chunk\": chunk\n",
    "        })\n",
    "    return [Send(\"summarize_chunk\", chunk) for chunk in chunks]\n",
    "\n",
    "\n",
    "def summarize_chunk(chunk):\n",
    "    chunk_id = chunk[\"id\"]\n",
    "    chunk_text = chunk[\"chunk\"]\n",
    "    response = llm.invoke(\n",
    "        f\"\"\"\n",
    "        이 텍스트들을 보기좋게 요약을 해주세요. 한국어 입니다.\n",
    "        텍스트: {chunk_text}\n",
    "        \"\"\"\n",
    "    )\n",
    "    summary = f\"[Chunk {chunk_id}] {response.content}\"\n",
    "    return {\n",
    "        \"summaries\": [summary]\n",
    "    }\n",
    "\n",
    "\n",
    "def mega_summary(state: State):\n",
    "    all_summaries = \"/n\".join(state[\"summaries\"])\n",
    "    prompt = f\"\"\"\n",
    "    요약본을 바탕으로 핵심키워드를 추출해서 요약본을 설명하는 요약본을 만들어줘 약 500자 내외면 좋겠어.\n",
    "    요약본:{all_summaries}\n",
    "    \"\"\"\n",
    "    response = llm.invoke(prompt)\n",
    "    return {\"mega_summarys\": response.content}\n",
    "\n",
    "\n",
    "def dispatch_artists(state: State):\n",
    "    return [\n",
    "        Send(\n",
    "            \"generate_thumbnail\", {\n",
    "                \"id\": i,\n",
    "                \"summary\": state[\"mega_summarys\"]\n",
    "            }\n",
    "        ) for i in [1, 2, 3]\n",
    "    ]\n",
    "\n",
    "\n",
    "def generate_thumbnail(args):\n",
    "    concept_id = args[\"id\"]\n",
    "    summary = args[\"summary\"]\n",
    "\n",
    "    prompt = f\"\"\"\n",
    "    이 요약본을 바탕으로, GPT images 생성기에 입력할 유튜브 썸네일을 만들기 위한 프롬프트를 만들어줘,\n",
    "    - 핵심적인 시각적 요소가 2~3개 포함되어야 하고 너무 많은 요소가 들어가지 않도록 해줘,\n",
    "    - 색상의 균형이 중요해,\n",
    "    - 타이틀이 들어갈 위치에 핵심키워드를 넣어줘.\n",
    "    요약본 : {summary}\n",
    "    \"\"\"\n",
    "\n",
    "    response = llm.invoke(prompt)\n",
    "\n",
    "    thumbnail_prompt = response.content\n",
    "\n",
    "    client = OpenAI()\n",
    "\n",
    "    result = client.images.generate(\n",
    "        model=\"gpt-image-1\",\n",
    "        prompt=thumbnail_prompt,\n",
    "        quality=\"low\",\n",
    "        moderation=\"low\",\n",
    "        size=\"auto\"\n",
    "    )\n",
    "\n",
    "    image_bytes = base64.b64decode(result.data[0].b64_json)\n",
    "    filename = f\"thumbnail_{concept_id}.jpg\"\n",
    "\n",
    "    with open(filename, \"wb\") as file:\n",
    "        file.write(image_bytes)\n",
    "\n",
    "    return {\n",
    "        \"thumbnail_prompt\": [thumbnail_prompt],\n",
    "        \"thumbnail_sketches\": [filename],\n",
    "    }\n",
    "\n",
    "\n",
    "def human_feedback(state: State):\n",
    "    answer = interrupt(\n",
    "        {\n",
    "            \"chosen_thumbnail\": \"어떤 썸네일이 제일 마음에 드시나요? \",\n",
    "            \"feedback\": \"최종 썸네일을 제작하기 위한 피드백을 주세요\"\n",
    "        }\n",
    "    )\n",
    "    user_feedback = answer[\"user_feedback\"]\n",
    "    chosen_prompt = answer[\"chosen_prompt\"]\n",
    "    return {\n",
    "        \"user_feedback\": user_feedback,\n",
    "        \"chosen_prompt\": state[\"thumbnail_prompt\"][chosen_prompt - 1],\n",
    "    }\n",
    "\n",
    "\n",
    "def generate_hd_thumbnail(state: State):\n",
    "    chosen_prompt = state[\"chosen_prompt\"]\n",
    "    user_feedback = state[\"user_feedback\"]\n",
    "\n",
    "    prompt = f\"\"\"\n",
    "    당신은 전문 유튜브 썸네일 디자이너입니다. 원본 썸네일 프롬프트를 가지고 사용자의 구체적인 피드백을 통합하여 개선된 버전을 만드세요.\n",
    "\n",
    "    **원본 프롬프트 (ORIGINAL PROMPT):**\n",
    "    {chosen_prompt}\n",
    "\n",
    "    **통합할 사용자 피드백 (USER FEEDBACK TO INCORPORATE):**\n",
    "    {user_feedback}\n",
    "\n",
    "    다음과 같은 내용을 담아 개선된 프롬프트를 만드세요:\n",
    "    1.  원본 프롬프트의 **핵심 개념을 유지**합니다.\n",
    "    2.  사용자가 요청한 피드백을 **구체적으로 다루고 구현**합니다.\n",
    "    3.  전문 유튜브 썸네일 제작 사양을 추가합니다:\n",
    "        * **고대비** 및 **굵고 선명한 시각적 요소**\n",
    "        * 시선을 사로잡는 **명확한 초점**\n",
    "        * **전문적인 조명과 구도**\n",
    "        * 가장자리에서 충분히 떨어지도록 **여백(패딩)을 넉넉하게 적용**한 **최적의 텍스트 배치 및 가독성**\n",
    "        * **주목을 끄는 톡톡 튀는 색상**\n",
    "        * **작은 썸네일 크기에서도 잘 작동하는 요소**\n",
    "        * **중요:** **항상** 텍스트와 이미지 경계 사이에 **충분한 여백/패딩을 확보**하세요.\n",
    "    \"\"\"\n",
    "\n",
    "    hd_response = llm.invoke(prompt)\n",
    "\n",
    "    final_thumbnail_prompt = hd_response.content\n",
    "\n",
    "    client = OpenAI()\n",
    "\n",
    "    result = client.images.generate(\n",
    "        model=\"gpt-image-1\",\n",
    "        prompt=final_thumbnail_prompt,\n",
    "        quality=\"high\",\n",
    "        moderation=\"low\",\n",
    "        size=\"auto\",\n",
    "    )\n",
    "\n",
    "    image_bytes = base64.b64decode(result.data[0].b64_json)\n",
    "\n",
    "    with open(\"thumbnail_final.jpg\", \"wb\") as file:\n",
    "        file.write(image_bytes)\n",
    "\n"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "from langgraph.checkpoint.memory import InMemorySaver\n",
    "\n",
    "graph_builder = StateGraph(State)\n",
    "\n",
    "(\n",
    "    graph_builder\n",
    "\n",
    "    .add_node(\"extract_audio\", extract_audio)\n",
    "    .add_node(\"transcribe_audio\", transcribe_audio)\n",
    "    .add_node(\"dispatch_summarizers\", dispatch_summarizers)\n",
    "    .add_node(\"summarize_chunk\", summarize_chunk)\n",
    "    .add_node(\"mega_summary\", mega_summary)\n",
    "    .add_node(\"dispatch_artists\", dispatch_artists)\n",
    "    .add_node(\"generate_thumbnail\", generate_thumbnail)\n",
    "    .add_node(\"human_feedback\", human_feedback)\n",
    "    .add_node(\"generate_hd_thumbnail\", generate_hd_thumbnail)\n",
    "\n",
    "    .add_edge(START, \"extract_audio\")\n",
    "    .add_edge(\"extract_audio\", \"transcribe_audio\")\n",
    "    .add_conditional_edges(\"transcribe_audio\", dispatch_summarizers, [\"summarize_chunk\"])\n",
    "    .add_edge(\"summarize_chunk\", \"mega_summary\")\n",
    "    .add_conditional_edges(\"mega_summary\", dispatch_artists, [\"generate_thumbnail\"])\n",
    "    .add_edge(\"generate_thumbnail\", \"human_feedback\")\n",
    "    .add_edge(\"human_feedback\", \"generate_hd_thumbnail\")\n",
    "    .add_edge(\"generate_hd_thumbnail\", END)\n",
    ")\n",
    "\n",
    "memory = InMemorySaver()\n",
    "graph = graph_builder.compile(checkpointer=memory)\n",
    "\n",
    "config = {\n",
    "    \"configurable\": {\n",
    "        \"thread_id\": \"3\",\n",
    "    },\n",
    "}"
   ],
   "id": "deaecedfde74300c",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "from langgraph.types import Command\n",
    "\n",
    "display(graph)\n",
    "graph.invoke(\n",
    "    {'video_file': 'video.mp4'},\n",
    "    config=config\n",
    "),\n",
    "\n"
   ],
   "id": "f8b18c0a42d8397b",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "response = {\n",
    "    \"user_feedback\": \"약간 3d 느낌을 추가해주고, 캐릭터 느낌으로 부탁해, 그리고 좌우 대칭이 잘 맞도록 이미지를 만들어줘\",\n",
    "    \"chosen_prompt\": 2,\n",
    "}\n",
    "\n",
    "graph.invoke(\n",
    "    Command(resume=response),\n",
    "    config=config,\n",
    ")"
   ],
   "id": "5fb7ea0d7b159710",
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
